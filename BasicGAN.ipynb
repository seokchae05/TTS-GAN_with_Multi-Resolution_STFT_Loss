{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import datetime\n",
    "import torchvision.utils as vutils\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.distributed.autograd as dist_autograd\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.distributed.optim import DistributedOptimizer\n",
    "##prarallel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "from Net import NetD, Encoder, Decoder, weights_init\n",
    "import Utils\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "from loss import l2_loss\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(size=[512,512]),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5, ))\n",
    "])\n",
    "dataset = Utils.vibrationData(root_path=root_path, transform=transform)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "validation_size = int(dataset_size * 0.1)\n",
    "test_size = dataset_size - train_size - validation_size\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
    "\n",
    "batch_size =4\n",
    "train_data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetG(nn.Module):\n",
    "    \"\"\"\n",
    "    GENERATOR NETWORK\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, isize, nz, nc, ngf, ngpu, extralayers):\n",
    "        super(NetG, self).__init__()\n",
    "        self.encoder1 = Encoder(isize, nz, nc, ngf, ngpu, extralayers)\n",
    "        self.decoder = Decoder(isize, nz, nc, ngf, ngpu, extralayers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent_i = self.encoder1(x)\n",
    "        gen_imag = self.decoder(latent_i)\n",
    "        return gen_imag, latent_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = NetD(isize=512, nc=4, ngf=64, ngpu=1, extralayers=0).to(device)\n",
    "G = NetG(isize=512, nz=100, nc=4, ngf=64, ngpu=1, extralayers=0).to(device)\n",
    "\n",
    "l_G = nn.L1Loss()\n",
    "l_D = nn.BCELoss()\n",
    "\n",
    "optim_D = optim.Adam(D.parameters(), lr=0.0002 ,betas=(0.5, 0.999))\n",
    "optim_G = optim.Adam(G.parameters(), lr=0.0002 ,betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "nowDatetime = now.strftime('test')\n",
    "writer = SummaryWriter(f'runs/{nowDatetime}')\n",
    "logger = logging.getLogger(__name__)\n",
    "fileHandler = logging.FileHandler('./train.log')\n",
    "logger.addHandler(fileHandler)\n",
    "logger.setLevel(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "n_epochs= 200\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    D_loss_acc = 0.0\n",
    "    G_loss_acc = 0.0\n",
    "    D.train()\n",
    "    G.train()\n",
    "\n",
    "    for i, (signal, images, corr_img, c) in enumerate(train_data_loader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "                \n",
    "        rand_z = torch.rand(images.size())\n",
    "        rand_z = rand_z.to(device)\n",
    "        \n",
    "        real_label = torch.ones (size=(batch_size,), dtype=torch.float32, device=device)\n",
    "        fake_label = torch.zeros(size=(batch_size,), dtype=torch.float32, device=device)\n",
    "        \n",
    "        \n",
    "        ## forward G and D\n",
    "        fake_img, _ = G(rand_z)\n",
    "        \n",
    "        pred_real, _ = D(images)\n",
    "        pred_fake, _ = D(fake_img.detach())\n",
    "        \n",
    "        \n",
    "        ## calculate err\n",
    "        optim_G.zero_grad()\n",
    "        optim_D.zero_grad()\n",
    "        \n",
    "        err_g = l_G(fake_img, images)\n",
    "        err_d_real = l_D(pred_real, real_label)\n",
    "        err_d_fake = l_D(pred_fake, fake_label)\n",
    "        err_d = (err_d_fake+err_d_real)*0.5\n",
    "        \n",
    "        ## backward G and D\n",
    "        err_g.backward(retain_graph=True)\n",
    "        optim_G.step()\n",
    "        \n",
    "        err_d.backward()\n",
    "        optim_D.step()\n",
    "        if err_d.item() < 1e-5:\n",
    "            D.apply(weights_init)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        D.eval()\n",
    "        G.eval()\n",
    "        \n",
    "        n_show = 10\n",
    "        with torch.no_grad():\n",
    "            real = images[:n_show]\n",
    "        \n",
    "            rand_z = torch.rand(images.size())\n",
    "            rand_z = rand_z.to(device)\n",
    "            \n",
    "            gener = G(rand_z)\n",
    "            real = real.reshape(n_show, 4, 512, 512)\n",
    "            writer.add_image(\n",
    "                \"fake\",\n",
    "                vutils.make_grid(gener.data[:n_show], normalize=True),\n",
    "                epoch\n",
    "            )\n",
    "            \n",
    "            writer.add_image(\n",
    "                \"real\",\n",
    "                vutils.make_grid(real.data[:n_show], normalize=True),\n",
    "                epoch\n",
    "            )\n",
    "        os.makedirs(f\"./weight/{nowDatetime}/{epoch}\")\n",
    "        torch.save({'D_state_dict': D.state_dict(),\n",
    "                'G_state_dict': G.state_dict()\n",
    "                },f\"./weight/{nowDatetime}/{epoch}/model_{epoch}.tar\")\n",
    "            \n",
    "            \n",
    "        writer.add_scalar(\"Enc_Gen_loss\",G_loss_acc/(len(dataset)/batch_size), epoch)\n",
    "        writer.add_scalar(\"dis_loss\", D_loss_acc/(len(dataset)/batch_size), epoch)\n",
    "        logger.info(f'loss_D : {D_loss_acc/(len(dataset)/batch_size)}, loss_EG : {G_loss_acc/(len(dataset)/batch_size)} at epoch-{epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vibration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7d95161f7bedbfa09496c29856a74c524c6bfebe9bd569c5b5b43dec9adf50b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
